{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hbWjQgDqnlH0"
   },
   "source": [
    "# Exercise sheet 9 - Introduction - Due date: June 29th"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KlEEvioinlH7"
   },
   "source": [
    "Submitted to:\n",
    "\n",
    "Mohamed Aborageh : s0moabor@uni-bonn.de\n",
    "\n",
    "Vinay Srinivas Bharadhwaj: s0vibhar@uni-bonn.de\n",
    "\n",
    "Yasamin Salimi: yasisali@uni-bonn.de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKKZz46jnlH8"
   },
   "source": [
    "# Exercise 1 - Basics of NN (9 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLAH0_bTnlH9"
   },
   "source": [
    "From the MNIST database load the handwritten digits dataset.\n",
    "1. Normalize your dataset before training your model. (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T23:13:14.326176Z",
     "start_time": "2021-06-28T23:13:08.772854Z"
    },
    "id": "H5yayFwinlH9"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T23:13:39.349198Z",
     "start_time": "2021-06-28T23:13:38.878402Z"
    },
    "id": "qvlq1CcvnlH-"
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist #28*28 image of handwritten of 0-9 \n",
    "(x_train, y_train),(x_test,y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1273,
     "status": "ok",
     "timestamp": 1624838592178,
     "user": {
      "displayName": "Faiza Khurshid",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQMg8YW9Vn-dmdh7YzAokK40kFWB3yOUQPXKFCNQ=s64",
      "userId": "09079498437295116932"
     },
     "user_tz": -120
    },
    "id": "hy4uMOFznlH_",
    "outputId": "e60b46ac-2d71-457b-b8bc-75cb68b83414",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data after normalizing is [[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00393124 0.02332955 0.02620568 0.02625207 0.17420356 0.17566281\n",
      "  0.28629534 0.05664824 0.51877786 0.71632322 0.77892406 0.89301644\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.05780486 0.06524513 0.16128198 0.22713296\n",
      "  0.22277047 0.32790981 0.36833534 0.3689874  0.34978968 0.32678448\n",
      "  0.368094   0.3747499  0.79066747 0.67980478 0.61494005 0.45002403\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.12250613 0.45858525 0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.32790981 0.36833534 0.3689874  0.34978968 0.32420121\n",
      "  0.15214552 0.17865984 0.25626376 0.1573102  0.12298801 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.04500225 0.4219755  0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.32790981 0.28826244 0.26543758 0.34149427 0.31128482\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.1541463  0.28272888 0.18358693 0.37314701\n",
      "  0.33153488 0.26569767 0.01601458 0.         0.05945042 0.19891229\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.0253731  0.00171577 0.22713296\n",
      "  0.33153488 0.11664776 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.20500962\n",
      "  0.33153488 0.24625638 0.00291174 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.01622378\n",
      "  0.24897876 0.32790981 0.10191096 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.04586451 0.31235677 0.32757096 0.23335172 0.14931733 0.00129164\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.10498298 0.34940902 0.3689874  0.34978968 0.15370495\n",
      "  0.04089933 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.06551419 0.27127137 0.34978968 0.32678448\n",
      "  0.245396   0.05882702 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.02333517 0.12857881 0.32549285\n",
      "  0.41390126 0.40743158 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.32161793\n",
      "  0.41390126 0.54251585 0.20001074 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.06697006 0.18959827 0.25300993 0.32678448\n",
      "  0.41390126 0.45100715 0.00625034 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.05110617 0.19182076 0.33339444 0.3689874  0.34978968 0.32678448\n",
      "  0.40899334 0.39653769 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.04117838 0.16813739\n",
      "  0.28960162 0.32790981 0.36833534 0.3689874  0.34978968 0.25961929\n",
      "  0.12760592 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.04431706 0.11961607 0.36545809 0.37314701\n",
      "  0.33153488 0.32790981 0.36833534 0.28877275 0.111988   0.00258328\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.05298497 0.42752138 0.4219755  0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.25273681 0.11646967 0.01312603 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.37491383 0.56222061\n",
      "  0.66525569 0.63253163 0.48748768 0.45852825 0.43408872 0.359873\n",
      "  0.17428513 0.01425695 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.92705966 0.82698729\n",
      "  0.74473314 0.63253163 0.4084877  0.24466922 0.22648107 0.02359823\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n",
      "Testing  Data after normalizing is [[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.34058377 0.55344342 0.51591571 0.47675838 0.16790986 0.06389561\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.90011425 0.75986285 0.82416724 0.80196443 0.71081842 0.42774558\n",
      "  0.31460214 0.29919608 0.35451095 0.35818467 0.34876618 0.33626817\n",
      "  0.34967436 0.335178   0.37058415 0.28257531 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.2716561  0.34104081 0.23362221 0.35993679 0.45615513 0.40289729\n",
      "  0.40358052 0.33999555 0.45477668 0.45948942 0.44740712 0.42458103\n",
      "  0.40442136 0.42997581 0.55369632 0.76077969 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.03017292\n",
      "  0.10486738 0.02115528 0.11996078 0.1212039  0.11801684 0.10020112\n",
      "  0.03708667 0.39950509 0.55369632 0.57601891 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.14658067 0.42828299 0.45560051 0.09781453 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.03736313\n",
      "  0.41148549 0.43166863 0.18093226 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.21908381\n",
      "  0.44857216 0.40289072 0.0959159  0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.10392528 0.4228827\n",
      "  0.44857216 0.10495473 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.23427223 0.43137432\n",
      "  0.33024801 0.00846409 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.01628112 0.3610963  0.42118438\n",
      "  0.10242986 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.2279357  0.44740712 0.30909499\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.13428445 0.45406238 0.42274688 0.09680447\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.02871073 0.39569152 0.45948942 0.29239993 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.0047667  0.30675154 0.45477668 0.39617395 0.06165059 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.06037819 0.38381719 0.45477668 0.13929404 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.05502122\n",
      "  0.35591353 0.38381719 0.20590283 0.00180901 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.23605877\n",
      "  0.40358052 0.38381719 0.09310389 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.17070836 0.42952046\n",
      "  0.40358052 0.38381719 0.09310389 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.33861822 0.450819\n",
      "  0.40358052 0.330929   0.07161837 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.33861822 0.450819\n",
      "  0.32890224 0.02719964 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "x_train = tf.keras.utils.normalize(x_train, axis = 1)\n",
    "x_test = tf.keras.utils.normalize(x_test,axis = 1)\n",
    "\n",
    "print(\"Training Data after normalizing is {}\".format(x_train[0]))\n",
    "print(\"Testing  Data after normalizing is {}\".format(x_test[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8z0Au8KWnlIA"
   },
   "source": [
    "2. Train a neural network once using Adam and once using AdaGrad optimizer.\n",
    "Hint: Set epochs = 20, neurons of hidden layer = 100, activation function =\n",
    "ReLU for reproducibility. (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O3A2AUErnlIB"
   },
   "outputs": [],
   "source": [
    "model_adam = tf.keras.models.Sequential()  # a basic feed-forward model\n",
    "model_adam.add(tf.keras.layers.Flatten())  # takes our 28x28 and makes it 1x784\n",
    "model_adam.add(tf.keras.layers.Dense(100, activation=tf.nn.relu))  # a simple fully-connected layer, 100 units, relu activation\n",
    "model_adam.add(tf.keras.layers.Dense(100, activation=tf.nn.relu))  # a simple fully-connected layer, 100 units, relu activation\n",
    "model_adam.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))  # our output layer. 10 units for 10 classes. Softmax for probability distribution\n",
    "\n",
    "model_adam.compile(optimizer='adam',  # Good default optimizer to start with\n",
    "              loss='sparse_categorical_crossentropy',  # how will we calculate our \"error.\" Neural network aims to minimize loss.\n",
    "              metrics=['accuracy'])  # what to track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 83689,
     "status": "ok",
     "timestamp": 1624838691352,
     "user": {
      "displayName": "Faiza Khurshid",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQMg8YW9Vn-dmdh7YzAokK40kFWB3yOUQPXKFCNQ=s64",
      "userId": "09079498437295116932"
     },
     "user_tz": -120
    },
    "id": "7ZxzVlE4nlIB",
    "outputId": "0031115b-0a5a-48c6-f909-9485f07f7e0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2838 - accuracy: 0.9168\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1198 - accuracy: 0.9633\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0816 - accuracy: 0.9746\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0619 - accuracy: 0.9798\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0472 - accuracy: 0.9850\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0374 - accuracy: 0.9878\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0309 - accuracy: 0.9894\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0253 - accuracy: 0.9914\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0199 - accuracy: 0.9936\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0195 - accuracy: 0.9930\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0142 - accuracy: 0.9954\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0140 - accuracy: 0.9953\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0120 - accuracy: 0.9960\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0116 - accuracy: 0.9960\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0102 - accuracy: 0.9965\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0096 - accuracy: 0.9966\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0088 - accuracy: 0.9970\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0091 - accuracy: 0.9966\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0068 - accuracy: 0.9977\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0091 - accuracy: 0.9970\n"
     ]
    }
   ],
   "source": [
    "adam=model_adam.fit(x_train, y_train, epochs=20)  # train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 66379,
     "status": "ok",
     "timestamp": 1624838920010,
     "user": {
      "displayName": "Faiza Khurshid",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQMg8YW9Vn-dmdh7YzAokK40kFWB3yOUQPXKFCNQ=s64",
      "userId": "09079498437295116932"
     },
     "user_tz": -120
    },
    "id": "QbWB0mlJ7ips",
    "outputId": "a6523309-abec-46e0-b955-337059c31165"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 1.9802 - accuracy: 0.4672\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 1.1274 - accuracy: 0.7869\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.7154 - accuracy: 0.8376\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5700 - accuracy: 0.8589\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4979 - accuracy: 0.8721\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4543 - accuracy: 0.8798\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4248 - accuracy: 0.8855\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4032 - accuracy: 0.8898\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3865 - accuracy: 0.8938\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3730 - accuracy: 0.8968\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3620 - accuracy: 0.8993\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3527 - accuracy: 0.9015\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3446 - accuracy: 0.9037\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3376 - accuracy: 0.9050\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3312 - accuracy: 0.9064\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3256 - accuracy: 0.9078\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3204 - accuracy: 0.9093\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3157 - accuracy: 0.9104\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3114 - accuracy: 0.9116\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3072 - accuracy: 0.9129\n"
     ]
    }
   ],
   "source": [
    "model_grad = tf.keras.models.Sequential()  # a basic feed-forward model\n",
    "model_grad.add(tf.keras.layers.Flatten())  # takes our 28x28 and makes it 1x784\n",
    "model_grad.add(tf.keras.layers.Dense(100, activation=tf.nn.relu))  # a simple fully-connected layer, 100 units, relu activation\n",
    "model_grad.add(tf.keras.layers.Dense(100, activation=tf.nn.relu))  # a simple fully-connected layer, 100 units, relu activation\n",
    "model_grad.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))  # our output layer. 10 units for 10 classes. Softmax for probability distribution\n",
    "\n",
    "model_grad.compile(optimizer='adagrad',  # Good default optimizer to start with\n",
    "              loss='sparse_categorical_crossentropy',  # how will we calculate our \"error.\" Neural network aims to minimize loss.\n",
    "              metrics=['accuracy'])  # what to track\n",
    "\n",
    "adagrad=model_grad.fit(x_train, y_train, epochs=20)  # train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKoa5EfMnlIC"
   },
   "source": [
    "3. Plot the SparseCategoricalCrossentropy loss for both models. Plot the computed\n",
    "accuracy for both models. Which model performed better while training?\n",
    "(2 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "executionInfo": {
     "elapsed": 420,
     "status": "ok",
     "timestamp": 1624839300112,
     "user": {
      "displayName": "Faiza Khurshid",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQMg8YW9Vn-dmdh7YzAokK40kFWB3yOUQPXKFCNQ=s64",
      "userId": "09079498437295116932"
     },
     "user_tz": -120
    },
    "id": "vBO3-anknlIC",
    "outputId": "78182883-5927-43dc-c4b8-79cad06be842"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot accuracy\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ep=np.arange(1,11,1)\n",
    "ada=adam.history['accuracy']\n",
    "adagrd=adagrad.history['accuracy']\n",
    "list_of_tuples = list(zip(ep,ada,adagrd )) \n",
    "\n",
    "df = pd.DataFrame(list_of_tuples, columns = ['Epoch','Adam','Adagrad'])\n",
    "df.index = df['Epoch']\n",
    "df.plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "executionInfo": {
     "elapsed": 484,
     "status": "ok",
     "timestamp": 1624839281972,
     "user": {
      "displayName": "Faiza Khurshid",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQMg8YW9Vn-dmdh7YzAokK40kFWB3yOUQPXKFCNQ=s64",
      "userId": "09079498437295116932"
     },
     "user_tz": -120
    },
    "id": "TLt5U3Dv9Vyr",
    "outputId": "4be8faf2-60b7-4d3e-d601-1c5cf5e0ecd4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss\n",
    "ep=np.arange(1,11,1)\n",
    "ada=adam.history['loss']\n",
    "adagrd=adagrad.history['loss']\n",
    "list_of_tuples = list(zip(ep,ada,adagrd )) \n",
    "\n",
    "df = pd.DataFrame(list_of_tuples, columns = ['Epoch','Adam','Adagrad'])\n",
    "\n",
    "df.index = df['Epoch']\n",
    "df.plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usX1htwbnlID"
   },
   "source": [
    "4. Compute the model accuracy on the test set for both optimizers. Which model\n",
    "performed better? (1 point)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 923,
     "status": "ok",
     "timestamp": 1624839342381,
     "user": {
      "displayName": "Faiza Khurshid",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQMg8YW9Vn-dmdh7YzAokK40kFWB3yOUQPXKFCNQ=s64",
      "userId": "09079498437295116932"
     },
     "user_tz": -120
    },
    "id": "e8Q_iyixnlID",
    "outputId": "31594dcf-47a2-45a1-bfc4-62d0ef75d6f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.1429 - accuracy: 0.9748\n",
      "0.14294207096099854\n",
      "0.9747999906539917\n"
     ]
    }
   ],
   "source": [
    "#adam\n",
    "val_loss, val_acc = model_adam.evaluate(x_test, y_test)   \n",
    "print(val_loss)  # model's loss (error)\n",
    "print(val_acc)  # model's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1304,
     "status": "ok",
     "timestamp": 1624839678632,
     "user": {
      "displayName": "Faiza Khurshid",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQMg8YW9Vn-dmdh7YzAokK40kFWB3yOUQPXKFCNQ=s64",
      "userId": "09079498437295116932"
     },
     "user_tz": -120
    },
    "id": "Gggreghv-QK5",
    "outputId": "68a683b1-0b60-4d47-cd3e-151fb9551658"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2975 - accuracy: 0.9179\n",
      "0.29745998978614807\n",
      "0.917900025844574\n"
     ]
    }
   ],
   "source": [
    "#adagrad\n",
    "val_loss, val_acc = model_grad.evaluate(x_test, y_test)   \n",
    "print(val_loss)  # model's loss (error)\n",
    "print(val_acc)  # model's accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R0StWSVcnlIE"
   },
   "source": [
    "5. Familiarize yourself with Layer Normalization and explain how it works. (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3sMIRs0c_nkJ"
   },
   "source": [
    "- layer normalization normalizes input across the features instead of normalizing input features across the batch dimension in batch normalization\n",
    "\n",
    "\n",
    "\n",
    "- layer normalization is very effective at stabilizing the hidden state dynamics in recurrent networks. Empirically, we show that layer normalization can substantially reduce the training time compared with previously published techniques.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Layer Normalization directly estimates the normalization statistics from the summed inputs to the neurons within a hidden layer so the normalization does not introduce any new dependencies between training cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3i-Z71U_nlIE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nvaUTra1nlIF"
   },
   "source": [
    "6. Using the same dataset to train a neural network with Layer Normalization. Hint:\n",
    "Set epochs = 20, neurons of hidden layer = 100, activation function = ReLU for\n",
    "reproducibility.\n",
    "\n",
    "\n",
    "a. Compute the SparseCategoricalCrossentropy loss and model accuracy.\n",
    "(1 point)\n",
    "\n",
    "\n",
    "b. Evaluate the model performance using the test dataset. (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B8aspb39nlIF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H7OeYGH_nlIG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kjglio3OnlIH"
   },
   "source": [
    "# Exercise 2 - Hyper Parameter Optimization (9 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p_CgeFTynlII"
   },
   "source": [
    "1. What are the main challenges with hyper-parameter optimization for neural\n",
    "networks? (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Dn7UY5rnlII"
   },
   "source": [
    "<b>Challenges with hyper-parameter optimization for neural networks:</b>\n",
    "\n",
    "\n",
    "\n",
    "1.) Overfitting is the issue in which our model performs extremely well during training and optimization, and very poorly out of sample\n",
    "\n",
    "\n",
    "\n",
    "2.)It is recommended that you optimize all hyperparameters of your model, including architecture parameters and model parameters, at the same time.\n",
    "\n",
    "\n",
    "\n",
    "3.) One of the drawbacks of grid search is that when it comes to dimensionality, it suffers when evaluating the number of hyperparameters grows exponentially. However, there is no guarantee that the search will produce the perfect solution, as it usually finds one by aliasing around the right set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SGrFXDzXnlIJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Yl_cTlNnlIJ"
   },
   "source": [
    "2. Inform yourself about variants of Bayesian-HPO and explain them in detail\n",
    "(2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CHRYyke-nlIK"
   },
   "source": [
    "The aim of Bayesian reasoning is to become “less wrong” with more data which these approaches do by continually updating the surrogate probability model after each evaluation of the objective function. The basic idea is: spend a little more time selecting the next hyperparameters in order to make fewer calls to the objective function.\n",
    "\n",
    "\n",
    "\n",
    "Sequential model-based optimization (SMBO) methods (SMBO) are a formalization of Bayesian optimization. The sequential refers to running trials one after another, each time trying better hyperparameters by applying Bayesian reasoning and updating a probability model (surrogate).\n",
    "\n",
    "\n",
    "\n",
    "There are five aspects of model-based hyperparameter optimization:\n",
    "\n",
    "\n",
    "\n",
    "A domain of hyperparameters over which to search\n",
    "An objective function which takes in hyperparameters and outputs a score that we want to minimize (or maximize)\n",
    "The surrogate model of the objective function\n",
    "A criteria, called a selection function, for evaluating which hyperparameters to choose next from the surrogate model\n",
    "\n",
    "\n",
    "\n",
    "A history consisting of (score, hyperparameter) pairs used by the algorithm to update the surrogate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G93_qvG1nlIK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RsenfGu5nlIL"
   },
   "source": [
    "3. Using the same MNIST dataset, optimize the activation function for the output\n",
    "layer and the number of dropout units in the NN model using the following\n",
    "methods. (6 points)\n",
    "\n",
    "a. Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T23:13:45.568013Z",
     "start_time": "2021-06-28T23:13:45.562222Z"
    },
    "id": "_F2-YypRnlIL"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from skopt import BayesSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T23:13:46.990461Z",
     "start_time": "2021-06-28T23:13:46.978147Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(activation,dropout_rate):\n",
    "    model_adam = tf.keras.models.Sequential()  \n",
    "    model_adam.add(tf.keras.layers.Flatten())  \n",
    "    model_adam.add(tf.keras.layers.Dense(100, activation=activation))  \n",
    "    model_adam.add(tf.keras.layers.Dense(100, activation=activation))  \n",
    "    model_adam.add(tf.keras.layers.Dense(10, activation=activation))  \n",
    "    model_adam.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "    model_adam.compile(optimizer='adam',  \n",
    "                  loss='sparse_categorical_crossentropy',  \n",
    "                  metrics=['accuracy']) \n",
    "    return model_adam\n",
    "\n",
    "model = KerasClassifier(build_fn = build_model, verbose=0)\n",
    "parameters = {'dropout_rate' : [0.0, 0.1, 0.2, 0.3, 0.4, 0.5],'activation' : ['relu', 'tanh', 'sigmoid', 'linear']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T23:20:41.650602Z",
     "start_time": "2021-06-28T23:13:48.672771Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohitha/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters by GridSearchCV: {'activation': 'sigmoid', 'dropout_rate': 0.0}\n"
     ]
    }
   ],
   "source": [
    "models = GridSearchCV(estimator = model, param_grid = parameters, n_jobs=1,scoring=\"accuracy\")\n",
    "best_model = models.fit(x_train,y_train)\n",
    "print(\"Best parameters by GridSearchCV:\", best_model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2o8SwiFdnlIM"
   },
   "source": [
    "b. Random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T23:23:12.800427Z",
     "start_time": "2021-06-28T23:20:53.156230Z"
    },
    "id": "Up11CXlnnlIM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters by Random search: {'dropout_rate': 0.1, 'activation': 'sigmoid'}\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=parameters,n_jobs=-1)\n",
    "random_search.fit(x_train,y_train)\n",
    "print(\"Best parameters by Random search:\",random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y49DBGcZnlIM"
   },
   "source": [
    "c. Bayesian Hyper-parameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T23:38:06.235301Z",
     "start_time": "2021-06-28T23:24:02.421943Z"
    },
    "id": "o4a9GhuvnlIM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohitha/opt/anaconda3/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/rohitha/opt/anaconda3/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/rohitha/opt/anaconda3/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/rohitha/opt/anaconda3/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/rohitha/opt/anaconda3/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/rohitha/opt/anaconda3/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/rohitha/opt/anaconda3/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/rohitha/opt/anaconda3/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/rohitha/opt/anaconda3/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/rohitha/opt/anaconda3/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/rohitha/opt/anaconda3/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/rohitha/opt/anaconda3/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/rohitha/opt/anaconda3/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/rohitha/opt/anaconda3/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/rohitha/opt/anaconda3/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/rohitha/opt/anaconda3/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/rohitha/opt/anaconda3/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/rohitha/opt/anaconda3/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/rohitha/opt/anaconda3/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/rohitha/opt/anaconda3/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/rohitha/opt/anaconda3/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/rohitha/opt/anaconda3/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/rohitha/opt/anaconda3/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/rohitha/opt/anaconda3/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/rohitha/opt/anaconda3/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/rohitha/opt/anaconda3/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/rohitha/opt/anaconda3/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/rohitha/opt/anaconda3/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/rohitha/opt/anaconda3/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/rohitha/opt/anaconda3/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/rohitha/opt/anaconda3/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/rohitha/opt/anaconda3/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/rohitha/opt/anaconda3/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/rohitha/opt/anaconda3/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/rohitha/opt/anaconda3/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters by Bayesian Hyper-parameter optimization: OrderedDict([('activation', 'sigmoid'), ('dropout_rate', 0.0)])\n"
     ]
    }
   ],
   "source": [
    "search = BayesSearchCV(estimator=model, search_spaces=parameters, n_jobs=-1)\n",
    "search.fit(x_train,y_train)\n",
    "print(\"Best parameters by Bayesian Hyper-parameter optimization:\", search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gIk5QjRanlIN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pwvTqK3nlIN"
   },
   "source": [
    "# Exercise 3 - Transfer Learning & CNNs (7 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhKjg3lenlIN"
   },
   "source": [
    "1. Load the VGG16 pre-trained model using Keras Applications API. Use the model\n",
    "to classify the dog images in canines.zip after pre-processing each image by\n",
    "doing the following: (2 points)\n",
    "\n",
    "\n",
    "a. Load each image and set the size to 224 x 224 pixels\n",
    "\n",
    "\n",
    "b. Convert the image pixels to a numpy array and reshape it according to the\n",
    "model’s input requirements\n",
    "\n",
    "\n",
    "c. Use the model to print out the predicted class and its probability for each\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "83pJLzrsnlIO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "khJGUZWxnlIO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = VGG16()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 1% of the probability of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog5.jpg\n",
      "Canines/dog5.jpg\n",
      "[[('n02109047', 'Great_Dane', 0.45382115)]]\n",
      "\n",
      "dog4.jpg\n",
      "Canines/dog4.jpg\n",
      "[[('n02106166', 'Border_collie', 0.735858)]]\n",
      "\n",
      "dog6.jpg\n",
      "Canines/dog6.jpg\n",
      "[[('n02109047', 'Great_Dane', 0.9088881)]]\n",
      "\n",
      "dog7.jpg\n",
      "Canines/dog7.jpg\n",
      "[[('n02109961', 'Eskimo_dog', 0.49961603)]]\n",
      "\n",
      "dog3.jpg\n",
      "Canines/dog3.jpg\n",
      "[[('n02099601', 'golden_retriever', 0.78778)]]\n",
      "\n",
      "dog2.jpg\n",
      "Canines/dog2.jpg\n",
      "[[('n02113023', 'Pembroke', 0.7457447)]]\n",
      "\n",
      "dog1.jpg\n",
      "Canines/dog1.jpg\n",
      "[[('n02107142', 'Doberman', 0.93426067)]]\n",
      "\n",
      "dog8.jpg\n",
      "Canines/dog8.jpg\n",
      "[[('n02107142', 'Doberman', 0.35419115)]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(\"Canines\"):\n",
    "    print(file)\n",
    "    img_path = 'Canines/'+file\n",
    "    print(img_path)\n",
    "    image = load_img(img_path, target_size=(224,224,3))\n",
    "    image = img_to_array(image)\n",
    "    image= image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    image = preprocess_input(image)\n",
    "    y_pred = model.predict(image)\n",
    "    label = decode_predictions(y_pred, top=1)\n",
    "    print(label)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 2% of the probability of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog5.jpg\n",
      "Canines/dog5.jpg\n",
      "[[('n02109047', 'Great_Dane', 0.45382115), ('n02108422', 'bull_mastiff', 0.43687198)]]\n",
      "\n",
      "dog4.jpg\n",
      "Canines/dog4.jpg\n",
      "[[('n02106166', 'Border_collie', 0.735858), ('n02106030', 'collie', 0.23651241)]]\n",
      "\n",
      "dog6.jpg\n",
      "Canines/dog6.jpg\n",
      "[[('n02109047', 'Great_Dane', 0.9088881), ('n02087394', 'Rhodesian_ridgeback', 0.07475051)]]\n",
      "\n",
      "dog7.jpg\n",
      "Canines/dog7.jpg\n",
      "[[('n02109961', 'Eskimo_dog', 0.49961603), ('n02110185', 'Siberian_husky', 0.2902289)]]\n",
      "\n",
      "dog3.jpg\n",
      "Canines/dog3.jpg\n",
      "[[('n02099601', 'golden_retriever', 0.78778), ('n02104029', 'kuvasz', 0.022645768)]]\n",
      "\n",
      "dog2.jpg\n",
      "Canines/dog2.jpg\n",
      "[[('n02113023', 'Pembroke', 0.7457447), ('n02113186', 'Cardigan', 0.2151999)]]\n",
      "\n",
      "dog1.jpg\n",
      "Canines/dog1.jpg\n",
      "[[('n02107142', 'Doberman', 0.93426067), ('n02087046', 'toy_terrier', 0.048935466)]]\n",
      "\n",
      "dog8.jpg\n",
      "Canines/dog8.jpg\n",
      "[[('n02107142', 'Doberman', 0.35419115), ('n02105412', 'kelpie', 0.19439045)]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(\"Canines\"):\n",
    "    print(file)\n",
    "    img_path = 'Canines/'+file\n",
    "    print(img_path)\n",
    "    image = load_img(img_path, target_size=(224,224,3))\n",
    "    image = img_to_array(image)\n",
    "    image= image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    image = preprocess_input(image)\n",
    "    y_pred = model.predict(image)\n",
    "    label = decode_predictions(y_pred, top=2)\n",
    "    print(label)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JdrLj_QBnlIO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJ5rAGGYnlIP"
   },
   "source": [
    "2. Downscale the given matrix by applying the following pooling operations:\n",
    "a. Max Pool (1 point)\n",
    "b. Average Pool (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Cped65WMnlIP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 3, 1), dtype=float32, numpy=\n",
       "array([[[[9.],\n",
       "         [9.],\n",
       "         [8.]],\n",
       "\n",
       "        [[9.],\n",
       "         [9.],\n",
       "         [8.]],\n",
       "\n",
       "        [[6.],\n",
       "         [7.],\n",
       "         [7.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid')\n",
    "\n",
    "Matrix = tf.constant([[1., 4., 1., 5.],\n",
    "                  [4., 9., 4., 8.],\n",
    "                  [4., 5., 4., 3.],\n",
    "                  [6., 5., 7., 4.]])\n",
    "Matrix = tf.reshape(Matrix, [1, 4, 4, 1])\n",
    "max_pool_2d = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n",
    "   strides=(1, 1), padding='valid')\n",
    "max_pool_2d(Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "dE23W75InlIP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 3, 1), dtype=float32, numpy=\n",
       "array([[[[4.5 ],\n",
       "         [4.5 ],\n",
       "         [4.5 ]],\n",
       "\n",
       "        [[5.5 ],\n",
       "         [5.5 ],\n",
       "         [4.75]],\n",
       "\n",
       "        [[5.  ],\n",
       "         [5.25],\n",
       "         [4.5 ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid')\n",
    "\n",
    "Matrix = tf.constant([[1., 4., 1., 5.],\n",
    "                  [4., 9., 4., 8.],\n",
    "                  [4., 5., 4., 3.],\n",
    "                  [6., 5., 7., 4.]])\n",
    "Matrix = tf.reshape(Matrix, [1, 4, 4, 1])\n",
    "avg_pool_2d = tf.keras.layers.AveragePooling2D(pool_size=(2, 2),\n",
    "   strides=(1, 1), padding='valid')\n",
    "avg_pool_2d(Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YG9wmBGxnlIQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lOwmoYK1nlIQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bq7qzWZtnlIQ"
   },
   "source": [
    "3. Load the CIFAR10 dataset using Keras datasets API and normalize the images’\n",
    "pixel values. Train a convolutional neural network to classify the dataset images\n",
    "with the following architecture: (3 points)\n",
    "\n",
    "\n",
    "a. Convolutional Base:\n",
    "\n",
    "\n",
    "i. An input convolution layer with 32 filters and a kernel size of (3,3).\n",
    "\n",
    "\n",
    "Adjust your input shape to that of the CIFAR images’ format\n",
    "\n",
    "\n",
    "ii. 2 convolution layers, each with 64 filters and a kernel size of (3,3)\n",
    "\n",
    "\n",
    "iii. 2 Max Pool layers, with a pool size of 2x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1r2_5dKDnlIR"
   },
   "source": [
    "b. 2 dense layers, with 64 and 10 units respectively. Adjust the output of the\n",
    "convolutional base such that it satisfies the input requirements of the\n",
    "dense layers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y1IHD26hnlIT"
   },
   "source": [
    "c. Use the following parameters to train the network:\n",
    "i. Sparse categorical cross entropy as your loss function\n",
    "ii. Adam optimizer\n",
    "iii. 10 epochs\n",
    "iv. ReLU activation for your layers\n",
    "\n",
    "Compile your model, then plot the accuracy across each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3pCgD4H6nlIT"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "from keras.callbacks import Callback\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QTAtIRqYnlIT"
   },
   "outputs": [],
   "source": [
    "data = tf.keras.datasets.cifar10.load_data()\n",
    "(Xtrain, ytrain), (Xtest, ytest) = data\n",
    "Xtrain = Xtrain.astype('float32')\n",
    "Xtest = Xtest.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5HNpVA7HnlIU"
   },
   "outputs": [],
   "source": [
    "#Normalize image pixels\n",
    "\n",
    "mean = np.mean(Xtrain, axis = (0,1,2,3))\n",
    "std = np.std(Xtrain, axis = (0,1,2,3))\n",
    "Xtrain = (Xtrain - mean) / (std +1e-7)\n",
    "Xtest = (Xtest - mean) / (std +1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r9DaMT1SnlIU"
   },
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "ytrain = np_utils.to_categorical(ytrain, n_classes)\n",
    "ytest = np_utils.to_categorical(ytest, n_classes)\n",
    "\n",
    "input_shape = (32, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8-tmbF7_nlIU"
   },
   "outputs": [],
   "source": [
    "def CNN():\n",
    "    '''Function to create model with given layers for CNN training'''\n",
    "    model = Sequential([\n",
    "    Conv2D(32, (3,3,), padding = 'same', activation = 'relu', input_shape = input_shape),\n",
    "    Conv2D(64, (3,3,), activation = 'relu'),\n",
    "    Conv2D(64, (3,3,), activation = 'relu'),\n",
    "    MaxPooling2D(pool_size = (2,2)),\n",
    "    MaxPooling2D(pool_size = (2,2)),\n",
    "              \n",
    "    Flatten(),\n",
    "    Dense(64, activation = 'relu'),\n",
    "    Dense(10, activation = 'softmax')])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 206,
     "status": "ok",
     "timestamp": 1624805557090,
     "user": {
      "displayName": "Priya Kempanna",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggpt26OmXFNJNbBMPrNopOcaEJVrWp4TvBjh0WjDtw=s64",
      "userId": "09701562998674055111"
     },
     "user_tz": -120
    },
    "id": "L89vSEyJogpT",
    "outputId": "191d6798-ac0c-4f50-f5dc-2f4d3d313c67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                200768    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 257,738\n",
      "Trainable params: 257,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "model = CNN()\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4461050,
     "status": "ok",
     "timestamp": 1624813860736,
     "user": {
      "displayName": "Priya Kempanna",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggpt26OmXFNJNbBMPrNopOcaEJVrWp4TvBjh0WjDtw=s64",
      "userId": "09701562998674055111"
     },
     "user_tz": -120
    },
    "id": "t4kFbcU6LMZw",
    "outputId": "8c5b25a6-3b43-414b-efed-7d294a134d56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 483s 309ms/step - loss: 0.3395 - accuracy: 0.8792 - val_loss: 1.0522 - val_accuracy: 0.7217\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 443s 284ms/step - loss: 0.2933 - accuracy: 0.8950 - val_loss: 1.2021 - val_accuracy: 0.7061\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 442s 283ms/step - loss: 0.2574 - accuracy: 0.9087 - val_loss: 1.3103 - val_accuracy: 0.7057\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 441s 282ms/step - loss: 0.2317 - accuracy: 0.9165 - val_loss: 1.3325 - val_accuracy: 0.7088\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 441s 282ms/step - loss: 0.2171 - accuracy: 0.9215 - val_loss: 1.4119 - val_accuracy: 0.7057\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 442s 283ms/step - loss: 0.1978 - accuracy: 0.9294 - val_loss: 1.4937 - val_accuracy: 0.7059\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 442s 283ms/step - loss: 0.1828 - accuracy: 0.9342 - val_loss: 1.5788 - val_accuracy: 0.6950\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 441s 282ms/step - loss: 0.1735 - accuracy: 0.9378 - val_loss: 1.6260 - val_accuracy: 0.7047\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 443s 284ms/step - loss: 0.1534 - accuracy: 0.9441 - val_loss: 1.7186 - val_accuracy: 0.7062\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 441s 282ms/step - loss: 0.1539 - accuracy: 0.9454 - val_loss: 1.8894 - val_accuracy: 0.6984\n",
      "1:14:20.835258\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "tbCallBack = TensorBoard(log_dir='./log', histogram_freq=1, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "starttime = datetime.datetime.now()\n",
    "\n",
    "history = model.fit(Xtrain, ytrain, batch_size=32, \n",
    "                   epochs=epochs, verbose=1, \n",
    "                   validation_data=(Xtest, ytest))\n",
    "\n",
    "endtime = datetime.datetime.now()\n",
    "print (endtime - starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "executionInfo": {
     "elapsed": 704,
     "status": "ok",
     "timestamp": 1624813979928,
     "user": {
      "displayName": "Priya Kempanna",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggpt26OmXFNJNbBMPrNopOcaEJVrWp4TvBjh0WjDtw=s64",
      "userId": "09701562998674055111"
     },
     "user_tz": -120
    },
    "id": "4mKGC7Pao8fn",
    "outputId": "4f555718-721d-44b0-9c78-d81b1c2d1e0a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3RU5b3/8fc3F0gChLtcEhSqyE0Ml3gXgWJ/B6uAiqhQrVaLSq23Vlsvp0rVrvaUrtPWU/Un9lc9WtSKVkorSkVFbcEKilpAaFFpCQKGQEIggdy+vz9mMs4kk2QCGQbYn9das2bvZz9772eGsD/7Ns82d0dERIIrLdUNEBGR1FIQiIgEnIJARCTgFAQiIgGnIBARCTgFgYhIwCkIREQCTkEghxQzW2pmO82sfarbkixmlmtmvzCzf5vZbjP7ODzeI9Vtk2BSEMghw8z6A2MAByYf5HVnHKT1tANeBYYBE4Fc4DSgBDh5P5Z3UNotRzYFgRxKvg68DTwOXBE9wcz6mdnvzazYzErM7FdR02aa2UdmVm5ma81sVLjczey4qHqPm9n94eFxZlZkZt83s63AY2bW1cz+FF7HzvBwftT83czsMTP7LDx9Qbh8tZlNiqqXaWbbzWxkE5/xaOACd1/r7nXu/rm73+fui/az3R+Z2XlR9TPCn6H+ezjVzJaZWamZfWBm46LqXmlmn4S/u0/N7GuJ/mPJkUNBIIeSrwPzwq//MLNeAGaWDvwJ+BfQH8gDnglPmwbMDs+bS+hIoiTB9fUGugHHANcQ+v/wWHj8aKAS+FVU/SeBHEJ780cBPw+XPwFcFlXvq8AWd18VZ51nAy+7++4E25hIu58GpkdN/w9gu7u/Z2Z5wIvA/eF5bgWeN7OeZtYBeAA4x907AacD7x9Au+QwpSCQQ4KZnUlow/asu78LfAzMCE8+GegL3Obue9x9r7v/JTztm8BP3X2Fh2xw938luNo64B533+fule5e4u7Pu3uFu5cDPwLGhtvXBzgHuM7dd7p7tbu/EV7Ob4GvmlluePxyQqERT3dgS4LtS6jdwFPAZDPLCU+fQSgcIBRQi9x9Ufjo4xVgJaGwql/WCWaW7e5b3H3NAbZNDkMKAjlUXAH82d23h8ef4ovTQ/2Af7l7TZz5+hEKjf1R7O5760fMLMfMHjGzf5nZLuBNoEv4iKQfsMPddzZciLt/BvwVmGpmXQgFxrwm1lkC9NnP9sZtt7tvAD4CJoXDYDKh7w9C4TotfFqo1MxKgTOBPu6+B7gEuA7YYmYvmtngA2ybHIZ0oUlSzsyygYuB9PB5b4D2hDbCBcAm4Ggzy4gTBpuAY5tYdAWhUzn1egNFUeMNu979LjAIOMXdt5rZCGAVYOH1dDOzLu5eGmdd/0vo6CQDWO7um5to0xLgfjPrEN4Qt0W74YvTQ2nA2nA4EG73k+4+M96K3H0xsDj8b3A/8CihC/YSIDoikEPB+UAtMBQYEX4NAd4idO7/HUKnU35iZh3MLMvMzgjP+2vgVjMbbSHHmdkx4WnvAzPMLN3MJhI+zdOMToSuC5SaWTfgnvoJ7r4FeAl4KHxROdPMzoqadwEwCriJ0DWDpjxJaOP8vJkNNrM0M+tuZneaWf3pmta2G0LXTP4PMIsvjgYgdNpqkpn9R3h5WeELzvlm1svMpoSvFewDdhM6VSQBoyCQQ8EVwGPu/m9331r/InSh9muE9sgnAccB/ya0d3wJgLvPJ3Qu/ymgnNAGuVt4uTeF5ysNL2dBC+34BZANbCd099LLDaZfDlQD64DPgZvrJ4TP1T8PDAB+39QK3H0foQvG64BXgF2Egq4H8Lf9bHd9UC0ndMH3d1Hlm4ApwJ1AMaEQuo3Q//004DvAZ8AOQoEzq6V1yZHH9GAakbZhZncDx7v7ZS1WFjmE6BqBSBsIn0q6mtBRg8hhRaeGRA6Qmc0kdMrlJXd/M9XtEWktnRoSEQk4HRGIiATcYXeNoEePHt6/f/9UN0NE5LDy7rvvbnf3nvGmHXZB0L9/f1auXJnqZohIQLg7tbW11NXVRd6jX21ZlkidCRMm0LFjx1Z/DjNrsuuVwy4IRESiuTtVVVXs2bOHPXv2UFFRERlurizRuhUVFan+iDHWr1/P8ccf36bLVBCIyH6rq6ujqqqKffv2UVVVFXm1drypOpWVlQltxGtra1P9VRw0dXVt/+NvBYHIYah+L3jv3r3s3buXysrKyHC88UTqNBxPZEMelA1weno6aWlpkVfD8XhlidTZn7IOHTq0+edTEIgkibtTWVnJrl27KC8vj3lvqmz37t0Jb9h16/cXMjIy6NChQ+SVk5MTM95UWSLlOTk5pKenp/ojJpWCQCSKu7Nv376EN9wtlQVhj7l9+/a0a9cu8l7/aji+P2VZWVkJbazbtWuX6q/hsKYgkENa/Ya5fq+4fs84+r2tyuo34NXV1an+2Amp31DWv7Kzs9tsvH379k1u4KPL0tPTMbNUfxVygBQE0ibq6urYs2cP5eXlMXvE8cYbTquoqGhyY324nwLJysqiU6dO5ObmkpubGxluqqxTp06RDXJLG+oj/XSFHDwKggCrra1t9Ua7qWm7d+8+rDfY0TIzMxPecLdUlpmZmeqPI9IiBcERZt++fWzbto2tW7c2+V4/XF5enurmJqRdu3aN9pKzs7PbvKx+I96+fftUf2SRg0pBcBiorq7m888/b3KDHv1eWhrvKYoHR05OTqPTHE0NR4/n5OQ0uZHWKRCR5FMQpEhtbS3FxcUt7rVv3bqVkpKSpLTBzGI2zPuzEa8f7tixozbYIocpBUEbc3dKS0vZvHkzRUVFbN68udFry5YtFBcXJ+UXgunp6fTq1YtevXrRu3fvJt979+5N586dSUtTB7QiQacgaIWamhq2bNkSs1GPt7GvrKxs0/WaGT179my0IY+3ke/evbs27iLSKgqCsPLy8ib34Os3+Nu2bWvTO2O6d+/e5N56dFmPHj3IyNA/lYgkRyC2Lrt372bdunXN7sW35R00HTp0ID8/n7y8vLivvn370qtXL91aKCKHhEAEwRtvvMF55513wMsxM4466qiYjXq8DX5ubq5+bSkih41ABEFeXl6Lddq3b9/sxj0/P58+ffpoL15EjjiBCIL8/HxOPPHEuBv3+uFu3bppL15EAikQQdCjRw8++OCDVDdDROSQpPsMRUQCTkEgIhJwCgIRkYBTEIiIBJyCQEQk4BQEIiIBpyAQEQk4BYGISMApCEREAk5BICIScAoCEZGAUxCIiARcUoPAzCaa2Xoz22Bmt8eZfrSZvW5mq8zsQzP7ajLbIyIijSUtCMwsHXgQOAcYCkw3s6ENqv0n8Ky7jwQuBR5KVntERCS+ZB4RnAxscPdP3L0KeAaY0qCOA7nh4c7AZ0lsj4iIxJHMIMgDNkWNF4XLos0GLjOzImARcEO8BZnZNWa20sxWFhcXJ6OtIiKBleqLxdOBx909H/gq8KSZNWqTu89190J3L+zZs+dBb6SIyJEsmUGwGegXNZ4fLot2NfAsgLsvB7KAHklsk4iINJDMIFgBDDSzAWbWjtDF4IUN6vwbmABgZkMIBYHO/YiIHERJCwJ3rwG+DSwGPiJ0d9AaM7vXzCaHq30XmGlmHwBPA1e6uyerTSIi0lhSH17v7osIXQSOLrs7angtcEYy2yAiIs1L9cViERFJMQWBiEjAKQhERAJOQSAiEnAKAhGRgFMQiIgEnIJARCTgFAQiIgGnIBARCTgFgYhIwCW1i4lDzUsvvcTGjRvJy8uLvI466ijS0pSHIhJcgQqCxx9/nGeffTamLCMjg969e8eEQ15eHhMnTqSgoCBFLRUROXgCFQSbNzd8HALU1NRQVFREUVFRTHnXrl0bBcGMGTP4/PPPG4VG3759ycvLo1evXmRkBOorFZEjQKC2WtOmTWPw4MFs3rw58tqxY0fcunl5DZ+qCX/5y1/YtGlTnNohaWlpkaOLRx55hJEjR8ZM/8c//kGvXr3Izc3FzA7swyRJbW0ttbW1tGvXLqa8tLSUrVu3Ul1dTXV1NVVVVU0O9+3bl7POOitm/qVLl/LWW2/F1K1/paWlkZmZSbt27cjMzKSwsJALLrggZv5ly5bxj3/8g8zMzJi68Yb79OlDr169YuavqKjA3WnXrh0ZGRmH7Pcvhx53P+L/XgIVBDfddFOjssrKSj777DM+++yzmIAYOnRoTL26ujq2bNnS7PLr6uoiy2p4ZFBTU8OQIUOoq6sjPT0dM4v8ccUbLi8vJz09PTL/hx9+yJlnnhlTp6n5jzrqKNauXRuz/iVLlnD55ZfH1K+trY3ZkFdVVeHunHTSSbzzzjsx8z/11FNcf/31zX7+elOmTGkUBK+++ir3339/QvNfddVVjYLgiSee4JFHHklo/v/8z//kvvvuiymbMWMGf/jDHyLjGRkZMQGSmZkZ+Q7nzJnDjBkzYuY/++yzWb16NdGPy2hq+KmnnuIrX/lKzPyDBw+muLg47jzRZWlpafzhD39gzJgxMfPPmTOH7OxsunXrRvfu3enevXtk+FDesYjH3dm9ezc7d+6ktLSUnTt3RoaPPfbYRp997ty5vPjii5GdlLq6uibfr7jiCmbNmhUz/w033MDLL7/c7Hz173PmzOGaa66Jmf+0005j1apVdOrUiU6dOpGbmxvzHj08depUTjzxxJj5169fT0ZGRqRuVlbWIffvFaggiCc7O5tjjz2WY489tsW6K1euZPPmzY1Co76suPiLh6s1PKLYtm0bdXV1QGivuyUN/1BqamooLy9P5CPFBEi9vXv3snXr1oTmr66ublSWmZmZ0LwAVVVVjcoaHmE0J17deG1qSry2Npy/pqaGmpqauPNXVFQ0KispKWHbtm0JrT/e59+5c2eTR58N5eTkxIzX1dVxxx13NPl3k56eHhMQ8+fPp0+fPpHp+/bt409/+lOjEMnOzk6oPfHU1NRQVlYW2YjXb8i7du3aKAQfe+wxHn744Zh6TX2WmTNnNgqCv//97yxc2PDhhvGNHz++UdmWLVvYsGFDQvPv3bu3UVlaWhpVVVWUlJRQUlLS7PxDhgxpFASTJk3in//8Z2Q8OhQahsoPf/jDRjuh8+fPJysri379+jFixIiEPkdrBT4IEpWWlkZBQUGzF5D37dvHli1b2Lx5M127do2ZVl5eznHHHcfmzZuprKxscX0HssdwoPPGm79bt24MGjQooVMzDU+JAYwZM4a77rqrUd2MjAzq6upiThXFm//000+npqYmoVNT0RvBepmZmWRnZ1NVVZVQEKdS9+7dY8bLysqabXNtbS3FxcWRHZH27dvHTN+6dSsXXXRRo/mys7Njjiy6d+9Ojx49eOihh2L+Bl555RV+9KMfxezBN7VTMmHChEZBsH37dlasWNH8hw4rLS1tVNaau/rifU+tmb9+Zy1avB2rpnTq1KlR2a5du2LGa2pqIqHY0K233hoz7u7MmDGDmpoaJk2alHAgtpYdbk+GLCws9JUrV6a6GfvN3amtrcXdI6/68ujx7OzsmP+MtbW17Nmzp8n5oofNjB49esSsd+/evezcuTNm/vT09EYb5tb80R+u6urqqKmpaXS9ol6XLl3o0KFDzDzbt2+PHEFE/7vEG87NzW20Md6xY0fk3ynePPXv1dXVdOvWLebfoaysjDlz5rBjx47IXmn08J49e2KWV1NTE7Pxe++99xg9enRC303nzp0bbYyfe+45pk2bltD8o0aN4t13340pe/TRRxudbsnJyaFr16506dKFrl27Rl6nnHIK3/rWt2Lqfvjhh3z66aekpaWRnp4eeY8ern/v27cvRx99dMz8mzdvZs+ePXHrN3zPzs5udETq7uzbt4/y8nJ27doV971++Otf/3qjswunnXYa27Zti9SNd8RYb+3atQwZMiQyXllZGTlCnDFjBvPmzWvhX6BpZvauuxfGm6YjgoPMzPbrzqL09HRyc3P3e71ZWVlx95SDKC0tjXbt2rXqdFXDYG2tbt267fe8nTt3bvb6yr59+yLBUFpa2mgPOCsri/PPP79RiMQ73dbwaARodHQLob/jzp07x2zMu3TpwqBBgxrVnTRpEsuXL49s7Lt06dKq7/7EE09sdLqlNeLd+NEaZkZWVhZZWVn07Nmz1fMvX748Zrw+VOIFSb9+/WLq1tbWcskll1BeXs6oUaMO6HM0R0cEIgFUf8G24dFFWloaF198cUzdnTt3smrVqpiNfm5urn6IeZhp7ohAQSAiEgDNBYEiXUQk4BQEIiIBpyAQEQk4BYGISMApCEREAk5BICIScAoCEZGAUxCIiAScgkBEJOAUBCIiAacgEBEJOAWBiEjAKQhERAJOQSAiEnAKAhGRgEtqEJjZRDNbb2YbzOz2JupcbGZrzWyNmT2VzPaIiEhjSXtUpZmlAw8CXwGKgBVmttDd10bVGQjcAZzh7jvN7KhktUdEROJL5hHBycAGd//E3auAZ4ApDerMBB50950A7v55EtsjIiJxJDMI8oBNUeNF4bJoxwPHm9lfzextM5uYxPaIiEgcSTs11Ir1DwTGAfnAm2Y23N1LoyuZ2TXANQBHH330wW6jiMgRLZlHBJuBflHj+eGyaEXAQnevdvdPgX8QCoYY7j7X3QvdvbBnz55Ja7CISBAlMwhWAAPNbICZtQMuBRY2qLOA0NEAZtaD0KmiT5LYJhERaSBpQeDuNcC3gcXAR8Cz7r7GzO41s8nhaouBEjNbC7wO3ObuJclqk4iINGbunuo2tEphYaGvXLky1c0QETmsmNm77l4Yb5p+WSwiEnAKAhGRgGsxCMxskpkpMEREjlCJbOAvAf5pZj81s8HJbpCIiBxcLQaBu18GjAQ+Bh43s+Vmdo2ZdUp660REJOkSOuXj7ruA5wj1F9QHuAB4z8xuSGLbRETkIGixi4nwPf/fAI4DngBOdvfPzSwHWAv8T3KbKCLxVFdXU1RUxN69e1PdFDmEZGVlkZ+fT2ZmZsLzJNLX0FTg5+7+ZnShu1eY2dWtbKOItJGioiI6depE//79MbNUN0cOAe5OSUkJRUVFDBgwIOH5Ejk1NBt4p37EzLLNrH94pa+2rpki0lb27t1L9+7dFQISYWZ079691UeJiQTBfKAuarw2XCYiKaYQkIb2528ikSDICD9YBoDwcLtWr0lEjiglJSWMGDGCESNG0Lt3b/Ly8iLjVVVVzc67cuVKbrzxxhbXcfrpp7dVcwG4+eabycvLo66uruXKAZLINYJiM5vs7gsBzGwKsD25zRKRQ1337t15//33AZg9ezYdO3bk1ltvjUyvqakhIyP+JqawsJDCwrjd3sRYtmxZ2zQWqKur44UXXqBfv3688cYbjB8/vs2WHa25z32oSuSI4DrgTjP7t5ltAr4PXJvcZonI4ejKK6/kuuuu45RTTuF73/se77zzDqeddhojR47k9NNPZ/369QAsXbqU8847DwiFyFVXXcW4ceP40pe+xAMPPBBZXseOHSP1x40bx0UXXcTgwYP52te+Rn2HmYsWLWLw4MGMHj2aG2+8MbLchpYuXcqwYcOYNWsWTz/9dKR827ZtXHDBBRQUFFBQUBAJnyeeeIITTzyRgoICLr/88sjne+655+K2b8yYMUyePJmhQ4cCcP755zN69GiGDRvG3LlzI/O8/PLLjBo1ioKCAiZMmEBdXR0DBw6kuLgYCAXWcccdFxk/GFqMLXf/GDjVzDqGx3cnvVUi0irJvFbQ2h6Ki4qKWLZsGenp6ezatYu33nqLjIwMlixZwp133snzzz/faJ5169bx+uuvU15ezqBBg5g1a1aj2x9XrVrFmjVr6Nu3L2eccQZ//etfKSws5Nprr+XNN99kwIABTJ8+vcl2Pf3000yfPp0pU6Zw5513Ul1dTWZmJjfeeCNjx47lhRdeoLa2lt27d7NmzRruv/9+li1bRo8ePdixY0eLn/u9995j9erVkbt1fvOb39CtWzcqKys56aSTmDp1KnV1dcycOTPS3h07dpCWlsZll13GvHnzuPnmm1myZAkFBQUczIdwJfSDMjM7F/gW8B0zu9vM7k5us0TkcDVt2jTS09MBKCsrY9q0aZxwwgnccsstrFmzJu485557Lu3bt6dHjx4cddRRbNu2rVGdk08+mfz8fNLS0hgxYgQbN25k3bp1fOlLX4psfJsKgqqqKhYtWsT5559Pbm4up5xyCosXLwbgtddeY9asWQCkp6fTuXNnXnvtNaZNm0aPHj0A6NatW4uf++STT465ZfOBBx6goKCAU089lU2bNvHPf/6Tt99+m7POOitSr365V111FU888QQQCpBvfOMbLa6vLSXyg7L/C+QA44FfAxcRdTupiEi0Dh06RIZ/8IMfMH78eF544QU2btzIuHHj4s7Tvn37yHB6ejo1NTX7VacpixcvprS0lOHDhwNQUVFBdnZ2k6eRmpKRkRG50FxXVxdzUTz6cy9dupQlS5awfPlycnJyGDduXLO3dPbr149evXrx2muv8c477zBv3rxWtetAJXJEcLq7fx3Y6e4/BE4j9EhJETlEuHvSXgeirKyMvLw8AB5//PE2+KSxBg0axCeffMLGjRsB+N3vfhe33tNPP82vf/1rNm7cyMaNG/n000955ZVXqKioYMKECTz88MMA1NbWUlZWxpe//GXmz59PSUnogYn1p4b69+/Pu+++C8DChQuprq6Ou76ysjK6du1KTk4O69at4+233wbg1FNP5c033+TTTz+NWS7AN7/5TS677LKYI6qDJZEgqI+xCjPrC1QT6m9IRKRZ3/ve97jjjjsYOXJkq/bgE5Wdnc1DDz3ExIkTGT16NJ06daJz584xdSoqKnj55Zc599xzI2UdOnTgzDPP5I9//CO//OUvef311xk+fDijR49m7dq1DBs2jLvuuouxY8dSUFDAd77zHQBmzpzJG2+8QUFBAcuXL485Cog2ceJEampqGDJkCLfffjunnnoqAD179mTu3LlceOGFFBQUcMkll0TmmTx5Mrt37z7op4UggUdVmtkPCPUnNAF4EHDgUXdPyXUCPapSJOSjjz5iyJAhqW5Gyu3evZuOHTvi7lx//fUMHDiQW265JdXNarWVK1dyyy238NZbbx3wsuL9bez3oyrDD6R51d1L3f154BhgcKpCQESkoUcffZQRI0YwbNgwysrKuPbaw+/u9p/85CdMnTqVH//4xylZfyJHBKvcfeRBak+LdEQgEqIjAmlKmx4RhL1qZlNNnZqIiByREgmCawl1MrfPzHaZWbmZ7Upyu0RE5CBJ5JfFeiSliMgRLJEflJ0Vr7zhg2pEROTwlMipoduiXj8A/kjoYTUiEmDjx4+PdNNQ7xe/+EWku4Z4xo0bR/3NHl/96lcpLS1tVGf27Nn87Gc/a3bdCxYsYO3atZHxu+++myVLlrSm+c0KWnfVLQaBu0+Ken0FOAHYmfymicihbPr06TzzzDMxZc8880yzHb9FW7RoEV26dNmvdTcMgnvvvZezzz57v5bVUMPuqpMlGT+w218JdTrXQBGge9ZEAu6iiy7ixRdfjPS3s3HjRj777DPGjBnDrFmzKCwsZNiwYdxzzz1x5+/fvz/bt4cebfKjH/2I448/njPPPDPSVTWEfiNw0kknUVBQwNSpU6moqGDZsmUsXLiQ2267jREjRvDxxx/HdA/96quvMnLkSIYPH85VV13Fvn37Iuu75557GDVqFMOHD2fdunVx2xXI7qoT6Gfkf4AHwq9fAX8BfpvMvk2ae40ePdpFxH3t2rUx4/fcc48T+uV/i6+ZM2c2Wt7MmTNj6txzzz0ttuHcc8/1BQsWuLv7j3/8Y//ud7/r7u4lJSXu7l5TU+Njx471Dz74wN3dx44d6ytWrHB392OOOcaLi4t95cqVfsIJJ/iePXu8rKzMjz32WJ8zZ467u2/fvj2yrrvuussfeOABd3e/4oorfP78+ZFp9eOVlZWen5/v69evd3f3yy+/3H/+859H1lc//4MPPuhXX3113M/0zW9+05944gkvKyvzvn37elVVlbu7X3zxxZFl1dTUeGlpqa9evdoHDhzoxcXFMZ+7Yfs6dOjg7u6vv/665+Tk+CeffBKZVj9PRUWFDxs2zLdv3+6ff/655+fnR+rV15k9e3akDYsXL/YLL7ww7mdo+Lfh7g6s9Ca2q4kcEawE3g2/lgPfd/fLDjyCRORwF316KPq00LPPPsuoUaMYOXIka9asiTmN09Bbb73FBRdcQE5ODrm5uUyePDkybfXq1YwZM4bhw4czb968Jruxrrd+/XoGDBjA8ceH+sW84oorePPNL+5rufDCCwEYPXp0pKO6aEHtrjqR56k9B+x191oAM0s3sxx3r2iTFojIYWvKlCnccsstvPfee1RUVDB69Gg+/fRTfvazn7FixQq6du3KlVde2WwXzM258sorWbBgAQUFBTz++OMsXbr0gNpb35V1U91YB7W76oR+WQxkR41nA213eV5E2sTs2bMTPsUafS663ty5c2PqzJ49u8V1duzYkfHjx3PVVVdFjgZ27dpFhw4d6Ny5M9u2beOll15qdhlnnXUWCxYsoLKykvLycv74xz9GppWXl9OnTx+qq6tjNnqdOnWivLy80bIGDRrExo0b2bBhAwBPPvkkY8eObfFz1Atqd9WJBEGWRz2eMjyc0yZrF5HD3vTp0/nggw8iQVBQUMDIkSMZPHgwM2bM4Iwzzmh2/lGjRnHJJZdQUFDAOeecw0knnRSZdt9993HKKadwxhlnMHjw4Ej5pZdeypw5cxg5ciQff/xxpDwrK4vHHnuMadOmMXz4cNLS0rjuuusS+hxB7q46kU7n/grc4O7vhcdHA79y99ParBWtoE7nRELU6VwwJdJddWs7nUvkGsHNwHwz+wwwoDdwSfOziIhIW/vJT37Cww8/3OaPskykr6EVZjYYGBQuWu/u8U94iYhI0tx+++3cfvvtbb7cFq8RmNn1QAd3X+3uq4GOZvatNm+JiIikRCIXi2e6e6RDEHffCcxMZOFmNtHM1pvZBjNrMsbCzztwM4t7/kpE4mvpGp8Ez/78TSQSBOnRD6Uxs3SgXUszhes9CJwDDAWmm1OpLPoAAAmXSURBVNnQOPU6ATcBf0u00SISukOmpKREYSAR7k5JSQlZWVmtmi+Ri8UvA78zs0fC49cCzd8YHHIysMHdPwEws2eAKUDDnxjeB/wXod5NRSRB+fn5FBUVtU1fM3LEyMrKIj8/v1XzJBIE3weuAepvxv2Q0J1DLckDNkWNFwGnRFcws1FAP3d/0cyaDAIzuybcBo4++ugEVi1y5MvMzIzpqkBkfyXSDXUdodM2Gwnt5X8Z+OhAV2xmacB/A99NoA1z3b3Q3Qt79ux5oKsWEZEoTR4RmNnxwPTwazvwOwB3H5/gsjcD/aLG88Nl9ToRerbB0vAliN7AQjOb7O76xZiIyEHS3KmhdcBbwHnuvgHAzG5pxbJXAAPNbAChALgUmFE/0d3LgB7142a2FLhVISAicnA1d2roQmAL8LqZPWpmEwj9sjgh7l4DfBtYTOhU0rPuvsbM7jWzyc3PLSIiB0sifQ11IHS3z3RC1weeAF5w9z8nv3mNqa8hEZHWa66voUQuFu9x96fcfRKh8/yrCN1JJCIiR4BWPbPY3XeG7+CZkKwGiYjIwbU/D68XEZEjiIJARCTgFAQiIgGnIBARCTgFgYhIwCkIREQCTkEgIhJwCgIRkYBTEIiIBJyCQEQk4BQEIiIBpyAQEQk4BYGISMApCEREAk5BICIScAoCEZGAUxCIiAScgkBEJOAUBCIiAacgEBEJOAWBiEjAKQhERAJOQSAiEnAKAhGRgFMQiIgEnIJARCTgFAQiIgGnIBARCTgFgYhIwCkIREQCTkEgIhJwCgIRkYBTEIiIBJyCQEQk4JIaBGY20czWm9kGM7s9zvTvmNlaM/vQzF41s2OS2R4REWksaUFgZunAg8A5wFBgupkNbVBtFVDo7icCzwE/TVZ7REQkvmQeEZwMbHD3T9y9CngGmBJdwd1fd/eK8OjbQH4S2yMiInEkMwjygE1R40XhsqZcDbwUb4KZXWNmK81sZXFxcRs2UUREDomLxWZ2GVAIzIk33d3nunuhuxf27Nnz4DZOROQIl5HEZW8G+kWN54fLYpjZ2cBdwFh335fE9oiISBzJPCJYAQw0swFm1g64FFgYXcHMRgKPAJPd/fMktkVERJqQtCBw9xrg28Bi4CPgWXdfY2b3mtnkcLU5QEdgvpm9b2YLm1iciIgkSTJPDeHui4BFDcrujho+O5nrFxGRlh0SF4tFRCR1FAQiIgGnIBARCTgFgYhIwCkIREQCTkEgIhJwCgIRkYBTEIiIBJyCQEQk4BQEIiIBpyAQEQk4BYGISMApCEREAk5BICIScAoCEZGAUxCIiAScgkBEJOAUBCIiAacgEBEJOAWBiEjAKQhERAJOQSAiEnAKAhGRgFMQiIgEnIJARCTgFAQiIgGnIBARCTgFgYhIwCkIREQCTkEgIhJwCgIRkYBTEIiIBJyCQEQk4BQEIiIBpyAQEQk4BYGISMApCEREAi6pQWBmE81svZltMLPb40xvb2a/C0//m5n1T2Z7RESksaQFgZmlAw8C5wBDgelmNrRBtauBne5+HPBz4L+S1R4REYkvmUcEJwMb3P0Td68CngGmNKgzBfjf8PBzwAQzsyS2SUREGshI4rLzgE1R40XAKU3VcfcaMysDugPboyuZ2TXANeHR3Wa2fj/b1KPhsgNO30csfR9f0HcR60j4Po5pakIyg6DNuPtcYO6BLsfMVrp7YRs06Yig7yOWvo8v6LuIdaR/H8k8NbQZ6Bc1nh8ui1vHzDKAzkBJEtskIiINJDMIVgADzWyAmbUDLgUWNqizELgiPHwR8Jq7exLbJCIiDSTt1FD4nP+3gcVAOvAbd19jZvcCK919IfD/gCfNbAOwg1BYJNMBn146wuj7iKXv4wv6LmId0d+HaQdcRCTY9MtiEZGAUxCIiARcYIKgpe4ugsLM+pnZ62a21szWmNlNqW7TocDM0s1slZn9KdVtSTUz62Jmz5nZOjP7yMxOS3WbUsXMbgn/P1ltZk+bWVaq25QMgQiCBLu7CIoa4LvuPhQ4Fbg+wN9FtJuAj1LdiEPEL4GX3X0wUEBAvxczywNuBArd/QRCN70k+4aWlAhEEJBYdxeB4O5b3P298HA5of/kealtVWqZWT5wLvDrVLcl1cysM3AWoTv6cPcqdy9NbatSKgPIDv/OKQf4LMXtSYqgBEG87i4CvfEDCPf2OhL4W2pbknK/AL4H1KW6IYeAAUAx8Fj4VNmvzaxDqhuVCu6+GfgZ8G9gC1Dm7n9ObauSIyhBIA2YWUfgeeBmd9+V6vakipmdB3zu7u+mui2HiAxgFPCwu48E9gCBvKZmZl0JnTkYAPQFOpjZZaltVXIEJQgS6e4iMMwsk1AIzHP336e6PSl2BjDZzDYSOmX4ZTP7bWqblFJFQJG71x8lPkcoGILobOBTdy9292rg98DpKW5TUgQlCBLp7iIQwt18/z/gI3f/71S3J9Xc/Q53z3f3/oT+Ll5z9yNyry8R7r4V2GRmg8JFE4C1KWxSKv0bONXMcsL/byZwhF44Pyx6Hz1QTXV3keJmpcoZwOXA383s/XDZne6+KIVtkkPLDcC88E7TJ8A3UtyelHD3v5nZc8B7hO62W8UR2tWEupgQEQm4oJwaEhGRJigIREQCTkEgIhJwCgIRkYBTEIiIBJyCQCTMzGrN7P2oV5v9otbM+pvZ6rZankhbCsTvCEQSVOnuI1LdCJGDTUcEIi0ws41m9lMz+7uZvWNmx4XL+5vZa2b2oZm9amZHh8t7mdkLZvZB+FXfLUG6mT0a7t/+z2aWHa5/Y/j5EB+a2TMp+pgSYAoCkS9kNzg1dEnUtDJ3Hw78ilBvpQD/A/yvu58IzAMeCJc/ALzh7gWE+ump/xX7QOBBdx8GlAJTw+W3AyPDy7kuWR9OpCn6ZbFImJntdveOcco3Al9290/CHfZtdffuZrYd6OPu1eHyLe7ew8yKgXx33xe1jP7AK+4+MDz+fSDT3e83s5eB3cACYIG7707yRxWJoSMCkcR4E8OtsS9quJYvrtGdS+gJeqOAFeGHoIgcNAoCkcRcEvW+PDy8jC8eXfg14K3w8KvALIg8C7lzUws1szSgn7u/Dnwf6Aw0OioRSSbteYh8ITuqR1YIPbe3/hbSrmb2IaG9+unhshsIPcnrNkJP9arvpfMmYK6ZXU1oz38WoSdcxZMO/DYcFgY8EPBHQ0oK6BqBSAvC1wgK3X17qtsikgw6NSQiEnA6IhARCTgdEYiIBJyCQEQk4BQEIiIBpyAQEQk4BYGISMD9f168g7D2Cyl3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], 'black', linewidth = 3.0)\n",
    "plt.plot(history.history['val_accuracy'], 'black', ls = '--', linewidth = 3.0)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'], loc = 'center right')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(ymin=0)\n",
    "plt.title('Accuracy Curves')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Kjglio3OnlIH"
   ],
   "name": "Exercise_Sheet_9_Ravinder_Kempanna_Voleti_Khurshid_Ambast .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
